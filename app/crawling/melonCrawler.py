from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from webdriver_manager.chrome import ChromeDriverManager
import time

class MelonCrawler:
    BASE_URL = "https://www.melon.com/chart/index.htm"  # ë©œë¡  ì‹¤ì‹œê°„ ì°¨íŠ¸ URL
    WEEKLY_CHART_URL = "https://www.melon.com/chart/week/index.htm?classCd={}" # ì£¼ê°„ ì¥ë¥´ URL

    GENRE_CODES = {
        "ballad": "GN0100",
        "dance": "GN0200",
        "hiphop": "GN0300",
        "randb": "GN0400",
        "indie": "GN0500",
        "rock": "GN0600"
    }

    def __init__(self):
        self.options = webdriver.ChromeOptions()
        self.options.add_argument("headless")  # í™”ë©´ ì—†ì´ ì‹¤í–‰
        self.options.add_argument("log-level=3")  # ë¶ˆí•„ìš”í•œ ë¡œê·¸ ì œê±°
        self.service = Service(ChromeDriverManager().install())

    def crawl_songs(self, limit=100):
        """ë©œë¡ ì—ì„œ ìƒìœ„ Nê°œì˜ ë…¸ë˜ í¬ë¡¤ë§"""
        driver = webdriver.Chrome(service=self.service, options=self.options)
        driver.get(self.BASE_URL)
        time.sleep(2)  # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°

        songs = []
        rows = driver.find_elements(By.CSS_SELECTOR, "tr.lst50") + driver.find_elements(By.CSS_SELECTOR, "tr.lst100")

        for row in rows[:limit]:
            try:
                song_id = row.find_element(By.CSS_SELECTOR, "input[type='checkbox']").get_attribute("value")
                song_name = row.find_element(By.CSS_SELECTOR, "div.rank01 > span > a").text
                artist_name = row.find_element(By.CSS_SELECTOR, "div.rank02 > a").text
                album_name = row.find_element(By.CSS_SELECTOR, "div.rank03 > a").text
                album_id = row.find_element(By.CSS_SELECTOR, "div.rank03 > a").get_attribute("href").split("'")[1]
                album_image = row.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                uri = f"https://www.melon.com/song/detail.htm?songId={song_id}"

                song_info = {
                    "id": song_id,
                    "song_name": song_name,
                    "artist_name_basket": [artist_name],
                    "album_id": album_id,
                    "album_name": album_name,
                    "album_image": album_image,
                    "uri": uri
                }
                songs.append(song_info)
            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

        driver.quit()
        return songs

    def crawl_weekly_genre_songs(self, genre="ballad", limit=100):
        """ğŸµ ì£¼ê°„ ì¸ê¸°ê³¡ í¬ë¡¤ë§ (ì¥ë¥´ë³„) - ì›í•˜ëŠ” ê³¡ ê°œìˆ˜ê¹Œì§€ í¬ë¡¤ë§ ê°€ëŠ¥"""
        if genre not in self.GENRE_CODES:
            print(f"ì˜ëª»ëœ ì¥ë¥´ ì„ íƒ: {genre}")
            return []

        genre_code = self.GENRE_CODES[genre]
        url = self.WEEKLY_CHART_URL.format(genre_code)

        songs = []
        song_ids = set()
        driver = webdriver.Chrome(service=self.service, options=self.options)
        driver.get(url)
        time.sleep(2)

        rows = driver.find_elements(By.CSS_SELECTOR, "tr.lst50") + driver.find_elements(By.CSS_SELECTOR, "tr.lst100")

        for row in rows[:limit]:
            try:
                song_id = row.find_element(By.CSS_SELECTOR, "input[type='checkbox']").get_attribute("value")
                if song_id in song_ids:
                    continue

                song_name = row.find_element(By.CSS_SELECTOR, "div.rank01 > span > a").text
                artist_name = row.find_element(By.CSS_SELECTOR, "div.rank02 > a").text
                album_name = row.find_element(By.CSS_SELECTOR, "div.rank03 > a").text
                album_id = row.find_element(By.CSS_SELECTOR, "div.rank03 > a").get_attribute("href").split("'")[1]
                album_image = row.find_element(By.CSS_SELECTOR, "img").get_attribute("src")
                uri = f"https://www.melon.com/song/detail.htm?songId={song_id}"

                song_info = {
                    "id": song_id,
                    "song_name": song_name,
                    "artist_name_basket": [artist_name],
                    "album_id": album_id,
                    "album_name": album_name,
                    "album_image": album_image,
                    "uri": uri
                }
                songs.append(song_info)
                song_ids.add(song_id)

            except Exception as e:
                print(f"ì˜¤ë¥˜ ë°œìƒ: {e}")

        driver.quit()
        return songs

    def crawl_song_details(self, song_id):
        """íŠ¹ì • ë…¸ë˜ IDë¡œ ì¥ë¥´, ê°€ì‚¬ í¬ë¡¤ë§"""
        driver = webdriver.Chrome(service=self.service, options=self.options)
        song_url = f"https://www.melon.com/song/detail.htm?songId={song_id}"
        driver.get(song_url)
        time.sleep(2)

        try:
            more_button = driver.find_elements(By.CSS_SELECTOR, "button.lyricButton")
            if more_button:
                more_button[0].click()
                time.sleep(1)

            lyrics = driver.find_element(By.CSS_SELECTOR, "div.lyric").text.replace("\n", " ")
        except:
            lyrics = ""

        try:
            genre = ""
            dt_elements = driver.find_elements(By.CSS_SELECTOR, "dl.list dt")

            for i, dt in enumerate(dt_elements):
                if dt.text.strip() == "ì¥ë¥´":
                    genre = driver.find_elements(By.CSS_SELECTOR, "dl.list dd")[i].text
                    break

        except Exception as e:
            print(f" ì¥ë¥´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
            genre = ""

        driver.quit()

        return {"lyrics": lyrics, "genre": genre}

    def crawl_songs_with_details(self, limit=100):
        """ë…¸ë˜ ëª©ë¡ê³¼ ê°€ì‚¬, ì¥ë¥´ í•¨ê»˜ í¬ë¡¤ë§"""
        songs = self.crawl_songs(limit)

        for song in songs:
            details = self.crawl_song_details(song["id"])
            song["lyrics"] = details["lyrics"]
            song["genre"] = details["genre"]

        return songs

    def crawl_songs_with_details_genre(self, genre, limit=100):
        """íŠ¹ì • ì¥ë¥´ì˜ ê³¡ì„ í¬ë¡¤ë§í•˜ê³ , ê°€ì‚¬ ë° ì¥ë¥´ ì •ë³´ë¥¼ ì¶”ê°€"""
        songs = self.crawl_weekly_genre_songs(genre=genre, limit=limit)

        for song in songs:
            details = self.crawl_song_details(song["id"])
            song["lyrics"] = details["lyrics"]
            song["genre"] = details["genre"]

        return songs