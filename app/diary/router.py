from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import extract, text, func
from app.database import get_db, get_mongodb, get_redis
from app.emotion.models import model_index_to_db_emotion_id
from app.emotion.router import predict_emotion
from app.statistics.models import EmotionStatistics
from app.user.auth import get_current_user
from app.diary.models import Diary
from app.diary.schemas import DiaryCreateRequest, DiaryUpdateRequest, DiaryResponse, DiaryCountResponse
from app.user.models import User
from app.embedding.models import kobert, save_diary_embedding, split_sentences, get_user_preferred_genres, \
    get_songs_by_genre, get_song_embeddings, calculate_similarity
from app.transaction import transactional_session
from typing import List
import logging
import json
import torch
import numpy as np
import heapq
import torch.nn.functional as F
from datetime import datetime

router = APIRouter()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ğŸ“ ì¼ê¸° ì‘ì„± API
@router.post("", response_model=DiaryResponse, status_code=201, summary="ì¼ê¸° ì‘ì„± & ë…¸ë˜ ì¶”ì²œ",
             description="ì¼ê¸°ë¥¼ ì‘ì„±í•˜ë©´ ìë™ìœ¼ë¡œ ì„ë² ë”©ì„ ì§„í–‰í•˜ê³ , ì‚¬ìš©ìì˜ ì„ í˜¸ ì¥ë¥´ ë‚´ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")
async def create_diary(
        diary_request: DiaryCreateRequest,
        current_user: User = Depends(get_current_user),
        db: Session = Depends(get_db),
        mongodb=Depends(get_mongodb)
):
    """
    1. ìƒˆë¡œìš´ ì¼ê¸°ë¥¼ DBì— ì €ì¥
    2. Kiwië¥¼ ì´ìš©í•´ ë¬¸ì¥ ë¶„ë¦¬ í›„ KoBERTë¡œ ì„ë² ë”©
    3. DiaryEmbedding í…Œì´ë¸”ì— ì €ì¥
    4. ìœ ì €ì˜ ì„ í˜¸ ì¥ë¥´ ê¸°ë°˜ìœ¼ë¡œ MongoDBì—ì„œ ë…¸ë˜ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    5. ê°€ì‚¬ì™€ ì¼ê¸° í…ìŠ¤íŠ¸ ì„ë² ë”© ê°’ ë¹„êµ í›„ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ ì¶”ì²œ
    """

    with transactional_session(db) as session:
        sentences = split_sentences(diary_request.content)
        logger.info(f"[ì¼ê¸° ë¬¸ì¥ ë¶„ë¦¬] - ì›ë³¸: {diary_request.content}")
        for idx, sentence in enumerate(sentences):
            logger.info(f"    â–¶ ë¬¸ì¥ {idx + 1}: {sentence}")

        embeddings = [kobert.get_embedding(sentence) for sentence in sentences if sentence.strip()]
        if not embeddings:
            logger.warning("KoBERT ì„ë² ë”© ê²°ê³¼ê°€ ì—†ìŒ")
            return {"message": "ì„ë² ë”©í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤."}

        logger.info(f"[KoBERT ì„ë² ë”© ì™„ë£Œ] - {len(embeddings)}ê°œ ë¬¸ì¥ ì²˜ë¦¬ ì™„ë£Œ")

        # 2) ìœ ì € ì„ í˜¸ ì¥ë¥´ ê°€ì ¸ì˜¤ê¸°
        user_id = current_user.id
        genre_names = get_user_preferred_genres(session, user_id)
        if not genre_names:
            logger.warning(f"ìœ ì € {user_id}ì˜ ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return {"message": "ìœ ì €ì˜ ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

        logger.info(f"ğŸµ [ìœ ì € ì„ í˜¸ ì¥ë¥´] - {genre_names}")

        # 3) MongoDBì—ì„œ í•´ë‹¹ ì¥ë¥´ì˜ ë…¸ë˜ ê°€ì ¸ì˜¤ê¸°
        songs = await get_songs_by_genre(mongodb, genre_names)
        if not songs:
            logger.warning("í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŒ")
            return {"message": "í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤."}

        song_ids = [song["id"] for song in songs]
        logger.info(f"ğŸ¼ [ê°€ì ¸ì˜¨ ë…¸ë˜ ê°œìˆ˜] - {len(songs)}")

        # 4) ë…¸ë˜ ê°€ì‚¬ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸° ë° ìœ ì‚¬ë„ ê³„ì‚°
        song_embeddings = get_song_embeddings(session, song_ids)
        best_match = calculate_similarity(embeddings[0], song_embeddings)  # ì²« ë²ˆì§¸ ë¬¸ì¥ë§Œ ë¹„êµ

        if not best_match:
            logger.warning("ìœ ì‚¬í•œ ê°€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return {"message": "ìœ ì‚¬í•œ ê°€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        song_id, best_idx, similarity_score = best_match
        matching_song = next((song for song in songs if song["id"] == str(song_id)), None)

        if matching_song is None:
            logger.error(f"ì¶”ì²œëœ song_id {song_id}ê°€ MongoDBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return {"message": "ì¶”ì²œëœ ë…¸ë˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # best_idxê°€ ê°€ì‚¬ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
        if best_idx >= len(matching_song["lyrics"]):
            logger.error(f"best_idx {best_idx}ê°€ ê°€ì‚¬ ë²”ìœ„ë¥¼ ì´ˆê³¼í•¨ (ê°€ì‚¬ ê°œìˆ˜: {len(matching_song['lyrics'])})")
            return {"message": "ìœ ì‚¬í•œ ê°€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        start = max(0, best_idx - 1)
        end = min(len(matching_song["lyrics"]), best_idx + 2)

        context_lyrics = matching_song["lyrics"][start:end]
        best_lyric = " ".join(context_lyrics)

        # 5) ëª¨ë“  ê³¼ì • ì™„ë£Œ í›„ ì¼ê¸° ì €ì¥ (íŠ¸ëœì­ì…˜ ë³´ì¥)
        new_diary = Diary(
            user_id=current_user.id,
            content=diary_request.content
        )
        session.add(new_diary)
        session.commit()
        session.refresh(new_diary)

        logger.info(f"[ğŸ“– ì¼ê¸° ì €ì¥ ì™„ë£Œ] - {new_diary.content}")

        save_diary_embedding(session, new_diary.id, embeddings)

        response_data = {
            "id": new_diary.id,
            "user_id": new_diary.user_id,
            "content": new_diary.content,
            "created_at": new_diary.created_at,
            "updated_at": new_diary.updated_at,
            "recommended_song": {
                "song_id": song_id,
                "song_name": matching_song.get("song_name", "ì œëª© ì—†ìŒ"),
                "best_lyric": best_lyric,
                "similarity_score": round(float(similarity_score), 4),
                "album_image": matching_song.get("album_image", "ì´ë¯¸ì§€ ì—†ìŒ"),
                "artist": matching_song.get("artist_name_basket", ["ì•„í‹°ìŠ¤íŠ¸ ì—†ìŒ"]),
                "genre": matching_song.get("genre", "ì¥ë¥´ ì—†ìŒ")
            }
        }

        logger.info(f" [ì‘ë‹µ ë°ì´í„°] - {json.dumps(response_data, ensure_ascii=False, indent=4, default=str)}")

        return response_data

@router.post("/main", response_model=DiaryResponse, status_code=201,
             summary="ì¼ê¸° ì‘ì„± & Top-3 ìœ ì‚¬ ê°€ì‚¬ ê¸°ë°˜ ë…¸ë˜ ì¶”ì²œ",
             description="ì¼ê¸°ë¥¼ ì‘ì„±í•˜ë©´ KoBERT ì„ë² ë”© í›„, ì„ í˜¸ ì¥ë¥´ ë‚´ì—ì„œ ê°€ì‚¬ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ Top-3 ë…¸ë˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")
async def create_diary_with_music_recommend_top3(
    diary_request: DiaryCreateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    mongodb = Depends(get_mongodb),
    redis = Depends(get_redis)
):
    with transactional_session(db) as session:
        # 1) ë¬¸ì¥ ë¶„ë¦¬
        sentences = split_sentences(diary_request.content)
        if not sentences:
            raise HTTPException(status_code=400, detail="ë¶„ì„í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

        sentence_confidences = []
        emotion_vote_counter = {}

        logger.info("[ë¬¸ì¥ë³„ ê°ì • ë¶„ì„ ì‹œì‘]")
        for idx, sentence in enumerate(sentences):
            if not sentence.strip():
                continue

            logger.info(f"    â–¶ ë¬¸ì¥ {idx + 1}: {sentence}")

            emotion_id, probabilities = predict_emotion(sentence)
            confidence = max(probabilities)

            logger.info(f"       â–¶ ë¬¸ì¥ {idx + 1} ì˜ˆì¸¡ ê°ì • ID: {emotion_id}, í™•ì‹ ë„: {confidence:.4f}")
            sentence_confidences.append((sentence, emotion_id, confidence))

            # Top-3 ê°ì • ëª¨ë‘ ëˆ„ì 
            probs_tensor = torch.tensor(probabilities)
            topk = torch.topk(probs_tensor, k=3)

            for i in range(3):
                emo_id = topk.indices[i].item()
                score = topk.values[i].item()

                if score < 0.05:
                    continue

                if emo_id not in emotion_vote_counter:
                    emotion_vote_counter[emo_id] = 0.0
                emotion_vote_counter[emo_id] += score

        # í™•ì‹ ë„ ì´í•©ì´ ê°€ì¥ ë†’ì€ ê°ì • ì„ íƒ
        emotion_id_full = max(emotion_vote_counter.items(), key=lambda x: x[1])[0]
        confidence_full = emotion_vote_counter[emotion_id_full]
        emotion_id_db = model_index_to_db_emotion_id[emotion_id_full]

        # 3) ì „ì²´ ê°ì • ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        logger.info("[ë¬¸ì¥ë³„ ê°ì • í†µê³„ ê¸°ë°˜ ì „ì²´ ê°ì • ë¶„ì„ ê²°ê³¼]")
        for emo_id, score in sorted(emotion_vote_counter.items(), key=lambda x: -x[1]):
            logger.info(f"    â–¶ ê°ì • ID={emo_id}, í™•ì‹ ë„ ì´í•©={score:.4f}")

        logger.info(f"    â–¶ ìµœì¢… ì „ì²´ ê°ì • ID: {emotion_id_full}, í™•ì‹ ë„ ì´í•©: {confidence_full:.4f}")

        # 4) ê°€ì¥ ê°ì •ì´ ê°•í•œ ë¬¸ì¥ ì„ íƒ
        best_sentence, best_emotion_id, best_confidence = max(sentence_confidences, key=lambda x: x[2])
        logger.info(f"[ê°ì •ì´ ê°€ì¥ ê°•í•œ ë¬¸ì¥ ì„ íƒ] {best_sentence} (ê°ì • ID={best_emotion_id}, í™•ì‹ ë„={best_confidence:.4f})")

        # 5) best_sentenceë¥¼ KoBERT ì„ë² ë”©
        combined_embedding = kobert.get_embedding(best_sentence)

        # 6) ì„ í˜¸ ì¥ë¥´ ì¡°íšŒ
        genre_names = get_user_preferred_genres(session, current_user.id)
        if not genre_names:
            raise HTTPException(status_code=400, detail="ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # 7) MongoDBì—ì„œ í•´ë‹¹ ì¥ë¥´ ë…¸ë˜ ê°€ì ¸ì˜¤ê¸°
        songs = await get_songs_by_genre(mongodb, genre_names)
        if not songs:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        logger.info(f"ğŸ¼ [ê°€ì ¸ì˜¨ ë…¸ë˜ ê°œìˆ˜] - {len(songs)}")

        # 8) ìœ ì‚¬ë„ ê³„ì‚° ë° Top-3 ì¶”ì²œê³¡ ì„ ì •
        heap = []
        counter = 0
        for song in songs:
            try:
                song_id = int(song["id"])
                cache_key = f"lyrics_emb:{song_id}"
                cached = await redis.get(cache_key)

                if cached:
                    lyrics_embedding = np.array(json.loads(cached))
                else:
                    result = session.execute(
                        text("SELECT embedding FROM songLyricsEmbedding WHERE song_id = :song_id"),
                        {"song_id": song_id}
                    ).fetchone()
                    if not result:
                        continue
                    lyrics_embedding = np.array(json.loads(result[0]))
                    await redis.set(cache_key, json.dumps(lyrics_embedding.tolist()))

                if len(lyrics_embedding.shape) != 2:
                    continue

                lyrics = song.get("lyrics", [])
                if len(lyrics) < 1 or len(lyrics_embedding) != len(lyrics):
                    continue

                for idx, block_emb in enumerate(lyrics_embedding):
                    similarity = F.cosine_similarity(
                        torch.tensor(combined_embedding).unsqueeze(0),
                        torch.tensor(block_emb).unsqueeze(0)
                    ).item()

                    heapq.heappush(heap, (
                        similarity,
                        counter,
                        {
                            "song_id": song["id"],
                            "lyric_chunk": [lyrics[idx]],  # ë¸”ëŸ­ í•˜ë‚˜ë§Œ
                            "similarity": similarity,
                            "metadata": {
                                "song_name": song.get("song_name"),
                                "album_image": song.get("album_image"),
                                "artist": song.get("artist_name_basket", []),
                                "genre": song.get("genre")
                            }
                        }
                    ))
                    counter += 1

            except Exception as e:
                logger.error(f"ë…¸ë˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        # ì´í›„ raw_top, top_3, recommended_songs ìƒì„±ì€ ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€
        raw_top = heapq.nlargest(10, heap, key=lambda x: (x[0], x[1]))

        seen_song_ids = set()
        top_3 = []
        for sim, _, match in raw_top:
            if match["song_id"] not in seen_song_ids:
                top_3.append((sim, match))
                seen_song_ids.add(match["song_id"])
            if len(top_3) >= 3:
                break

        if not top_3:
            raise HTTPException(status_code=404, detail="ì í•©í•œ ë…¸ë˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 9) ì¼ê¸° ì €ì¥
        new_diary = Diary(
            user_id=current_user.id,
            content=diary_request.content,
            emotiontype_id=emotion_id_db,
            confidence=confidence_full,
            best_sentence=best_sentence,
            created_at=datetime.utcnow()
        )
        session.add(new_diary)
        session.commit()
        session.refresh(new_diary)

        save_diary_embedding(session, new_diary.id, combined_embedding)

        # 9-1) ê°ì • í†µê³„ ì—…ë°ì´íŠ¸ ë˜ëŠ” ì¶”ê°€
        existing_stat = session.query(EmotionStatistics).filter(
            EmotionStatistics.user_id == current_user.id,
            EmotionStatistics.year == new_diary.created_at.year,
            EmotionStatistics.month == new_diary.created_at.month,
            EmotionStatistics.emotiontype_id == emotion_id_db
        ).first()

        if existing_stat:
            existing_stat.count += 1
        else:
            new_stat = EmotionStatistics(
                user_id=current_user.id,
                year=new_diary.created_at.year,
                month=new_diary.created_at.month,
                emotiontype_id=emotion_id_db,
                quadrant=None,  # quadrant ë‚˜ì¤‘ì— ì¶”ê°€í• ê±°ë©´ ë§¤í•‘
                count=1,
                created_at=new_diary.created_at
            )
            session.add(new_stat)

        # 10) ì‘ë‹µ êµ¬ì„±
        recommended_songs = [
            {
                "song_id": match["song_id"],
                "song_name": match["metadata"]["song_name"],
                "best_lyric": " ".join(match["lyric_chunk"]),
                "similarity_score": round(float(sim), 4),
                "album_image": match["metadata"]["album_image"],
                "artist": match["metadata"]["artist"],
                "genre": match["metadata"]["genre"]
            }
            for sim, match in top_3
        ]

        response_data = {
            "id": new_diary.id,
            "user_id": new_diary.user_id,
            "content": new_diary.content,
            "emotiontype_id": emotion_id_db,
            "confidence": confidence_full,
            "created_at": new_diary.created_at,
            "updated_at": new_diary.updated_at,
            "recommended_songs": recommended_songs
        }

        logger.info("ì¶”ì²œ ê²°ê³¼: %s", json.dumps(response_data, indent=2, ensure_ascii=False, default=str))
        return response_data


@router.get("/{diary_id}", response_model=DiaryResponse,
            summary="ì¼ê¸° ì¡°íšŒ",
            description="íŠ¹ì • ì¼ê¸°ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_diary(
    diary_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return diary

@router.get("", response_model=List[DiaryResponse],
            summary="ë‚´ ì¼ê¸° ëª©ë¡ ì¡°íšŒ",
            description="ë¡œê·¸ì¸í•œ ì‚¬ìš©ìê°€ ì‘ì„±í•œ ëª¨ë“  ì¼ê¸°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_all_diaries(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diaries = db.query(Diary).filter(
        Diary.user_id == current_user.id
    ).all()

    return diaries

@router.put("/{diary_id}", response_model=DiaryResponse,
            summary="ì¼ê¸° ìˆ˜ì •",
            description="ì‘ì„±í•œ ì¼ê¸°ì˜ ë‚´ìš©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.")
def update_diary(
    diary_id: int,
    diary_update: DiaryUpdateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if diary_update.content:
        diary.content = diary_update.content

    db.commit()
    db.refresh(diary)

    return diary

@router.delete("/{diary_id}",
               summary="ì¼ê¸° ì‚­ì œ",
               description="ì‘ì„±í•œ ì¼ê¸°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
def delete_diary(
    diary_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    db.delete(diary)
    db.commit()

    return {"message": "ì¼ê¸°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!"}

@router.get("/{year}/{month}", response_model=List[DiaryResponse],
            summary="íŠ¹ì • ì—°ë„/ì›”ì˜ ì¼ê¸° ì¡°íšŒ",
            description="ì…ë ¥í•œ ì—°ë„ì™€ ì›”ì— í•´ë‹¹í•˜ëŠ” ì¼ê¸°ë¥¼ ëª¨ë‘ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_diaries_by_month(
    year: int,
    month: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diaries = db.query(Diary).filter(
        Diary.user_id == current_user.id,
        extract("year", Diary.created_at) == year,
        extract("month", Diary.created_at) == month
    ).all()

    if not diaries:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì—°ë„ì™€ ì›”ì— ì‘ì„±ëœ ì¼ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return diaries


@router.get("/{year}/{month}/count", response_model=DiaryCountResponse,
            summary="íŠ¹ì • ì—°/ì›”ì˜ ì¼ê¸° ê°œìˆ˜ ì¡°íšŒ",
            description="ì…ë ¥í•œ ì—°ë„ì™€ ì›”ì— í•´ë‹¹í•˜ëŠ” ì¼ê¸° ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
def get_diary_count_by_month(
    year: int,
    month: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if month < 1 or month > 12:
        raise HTTPException(status_code=400, detail="ì›”(month)ì€ 1~12 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    diary_count = db.query(func.count(Diary.id)).filter(
        Diary.user_id == current_user.id,
        extract("year", Diary.created_at) == year,
        extract("month", Diary.created_at) == month
    ).scalar()

    return DiaryCountResponse(
        user_id=current_user.id,
        year=year,
        month=month,
        diary_count=diary_count
    )
