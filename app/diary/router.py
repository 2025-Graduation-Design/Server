from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import extract, text
from app.database import get_db, get_mongodb, get_redis
from app.emotion.models import model_index_to_db_emotion_id
from app.emotion.router import predict_emotion
from app.statistics.models import EmotionStatistics
from app.user.auth import get_current_user
from app.diary.models import Diary
from app.diary.schemas import DiaryCreateRequest, DiaryUpdateRequest, DiaryResponse
from app.user.models import User
from app.embedding.models import kobert, save_diary_embedding, split_sentences, get_user_preferred_genres, \
    get_songs_by_genre, get_song_embeddings, calculate_similarity
from app.transaction import transactional_session
from typing import List
import logging
import json
import torch
import numpy as np
import heapq
import torch.nn.functional as F
from datetime import datetime

router = APIRouter()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

LYRIC_WINDOW_SIZE = 3  # ê°€ì‚¬ ë¹„êµ ë‹¨ìœ„ (3ì¤„)
MIN_LYRIC_LINES = 5    # ìµœì†Œ ê°€ì‚¬ ì¤„ ìˆ˜ í•„í„°ë§

# ğŸ“ ì¼ê¸° ì‘ì„± API
@router.post("", response_model=DiaryResponse, status_code=201, summary="ì¼ê¸° ì‘ì„± & ë…¸ë˜ ì¶”ì²œ",
             description="ì¼ê¸°ë¥¼ ì‘ì„±í•˜ë©´ ìë™ìœ¼ë¡œ ì„ë² ë”©ì„ ì§„í–‰í•˜ê³ , ì‚¬ìš©ìì˜ ì„ í˜¸ ì¥ë¥´ ë‚´ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")
async def create_diary(
        diary_request: DiaryCreateRequest,
        current_user: User = Depends(get_current_user),
        db: Session = Depends(get_db),
        mongodb=Depends(get_mongodb)
):
    """
    1. ìƒˆë¡œìš´ ì¼ê¸°ë¥¼ DBì— ì €ì¥
    2. Kiwië¥¼ ì´ìš©í•´ ë¬¸ì¥ ë¶„ë¦¬ í›„ KoBERTë¡œ ì„ë² ë”©
    3. DiaryEmbedding í…Œì´ë¸”ì— ì €ì¥
    4. ìœ ì €ì˜ ì„ í˜¸ ì¥ë¥´ ê¸°ë°˜ìœ¼ë¡œ MongoDBì—ì„œ ë…¸ë˜ ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
    5. ê°€ì‚¬ì™€ ì¼ê¸° í…ìŠ¤íŠ¸ ì„ë² ë”© ê°’ ë¹„êµ í›„ ê°€ì¥ ìœ ì‚¬í•œ ë…¸ë˜ ì¶”ì²œ
    """

    with transactional_session(db) as session:
        sentences = split_sentences(diary_request.content)
        logger.info(f"[ì¼ê¸° ë¬¸ì¥ ë¶„ë¦¬] - ì›ë³¸: {diary_request.content}")
        for idx, sentence in enumerate(sentences):
            logger.info(f"    â–¶ ë¬¸ì¥ {idx + 1}: {sentence}")

        embeddings = [kobert.get_embedding(sentence) for sentence in sentences if sentence.strip()]
        if not embeddings:
            logger.warning("KoBERT ì„ë² ë”© ê²°ê³¼ê°€ ì—†ìŒ")
            return {"message": "ì„ë² ë”©í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤."}

        logger.info(f"[KoBERT ì„ë² ë”© ì™„ë£Œ] - {len(embeddings)}ê°œ ë¬¸ì¥ ì²˜ë¦¬ ì™„ë£Œ")

        # 2) ìœ ì € ì„ í˜¸ ì¥ë¥´ ê°€ì ¸ì˜¤ê¸°
        user_id = current_user.id
        genre_names = get_user_preferred_genres(session, user_id)
        if not genre_names:
            logger.warning(f"ìœ ì € {user_id}ì˜ ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return {"message": "ìœ ì €ì˜ ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

        logger.info(f"ğŸµ [ìœ ì € ì„ í˜¸ ì¥ë¥´] - {genre_names}")

        # 3) MongoDBì—ì„œ í•´ë‹¹ ì¥ë¥´ì˜ ë…¸ë˜ ê°€ì ¸ì˜¤ê¸°
        songs = await get_songs_by_genre(mongodb, genre_names)
        if not songs:
            logger.warning("í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŒ")
            return {"message": "í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤."}

        song_ids = [song["id"] for song in songs]
        logger.info(f"ğŸ¼ [ê°€ì ¸ì˜¨ ë…¸ë˜ ê°œìˆ˜] - {len(songs)}")

        # 4) ë…¸ë˜ ê°€ì‚¬ ì„ë² ë”© ë¶ˆëŸ¬ì˜¤ê¸° ë° ìœ ì‚¬ë„ ê³„ì‚°
        song_embeddings = get_song_embeddings(session, song_ids)
        best_match = calculate_similarity(embeddings[0], song_embeddings)  # ì²« ë²ˆì§¸ ë¬¸ì¥ë§Œ ë¹„êµ

        if not best_match:
            logger.warning("ìœ ì‚¬í•œ ê°€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return {"message": "ìœ ì‚¬í•œ ê°€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        song_id, best_idx, similarity_score = best_match
        matching_song = next((song for song in songs if song["id"] == str(song_id)), None)

        if matching_song is None:
            logger.error(f"ì¶”ì²œëœ song_id {song_id}ê°€ MongoDBì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return {"message": "ì¶”ì²œëœ ë…¸ë˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        # best_idxê°€ ê°€ì‚¬ ë²”ìœ„ë¥¼ ë²—ì–´ë‚˜ì§€ ì•ŠëŠ”ì§€ í™•ì¸
        if best_idx >= len(matching_song["lyrics"]):
            logger.error(f"best_idx {best_idx}ê°€ ê°€ì‚¬ ë²”ìœ„ë¥¼ ì´ˆê³¼í•¨ (ê°€ì‚¬ ê°œìˆ˜: {len(matching_song['lyrics'])})")
            return {"message": "ìœ ì‚¬í•œ ê°€ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        start = max(0, best_idx - 1)
        end = min(len(matching_song["lyrics"]), best_idx + 2)

        context_lyrics = matching_song["lyrics"][start:end]
        best_lyric = " ".join(context_lyrics)

        # 5) ëª¨ë“  ê³¼ì • ì™„ë£Œ í›„ ì¼ê¸° ì €ì¥ (íŠ¸ëœì­ì…˜ ë³´ì¥)
        new_diary = Diary(
            user_id=current_user.id,
            content=diary_request.content
        )
        session.add(new_diary)
        session.commit()
        session.refresh(new_diary)

        logger.info(f"[ğŸ“– ì¼ê¸° ì €ì¥ ì™„ë£Œ] - {new_diary.content}")

        save_diary_embedding(session, new_diary.id, embeddings)

        response_data = {
            "id": new_diary.id,
            "user_id": new_diary.user_id,
            "content": new_diary.content,
            "created_at": new_diary.created_at,
            "updated_at": new_diary.updated_at,
            "recommended_song": {
                "song_id": song_id,
                "song_name": matching_song.get("song_name", "ì œëª© ì—†ìŒ"),
                "best_lyric": best_lyric,
                "similarity_score": round(float(similarity_score), 4),
                "album_image": matching_song.get("album_image", "ì´ë¯¸ì§€ ì—†ìŒ"),
                "artist": matching_song.get("artist_name_basket", ["ì•„í‹°ìŠ¤íŠ¸ ì—†ìŒ"]),
                "genre": matching_song.get("genre", "ì¥ë¥´ ì—†ìŒ")
            }
        }

        logger.info(f" [ì‘ë‹µ ë°ì´í„°] - {json.dumps(response_data, ensure_ascii=False, indent=4, default=str)}")

        return response_data


@router.post("/main", response_model=DiaryResponse, status_code=201,
             summary="ì¼ê¸° ì‘ì„± & Top-3 ìœ ì‚¬ ê°€ì‚¬ ê¸°ë°˜ ë…¸ë˜ ì¶”ì²œ",
             description="ì¼ê¸°ë¥¼ ì‘ì„±í•˜ë©´ KoBERT ì„ë² ë”© í›„, ì„ í˜¸ ì¥ë¥´ ë‚´ì—ì„œ ê°€ì‚¬ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ Top-3 ë…¸ë˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")
async def create_diary_with_music_recommend_top3(
    diary_request: DiaryCreateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    mongodb = Depends(get_mongodb),
    redis = Depends(get_redis)
):
    """MySQL songLyricsEmbedding í…Œì´ë¸” êµ¬ì¡°ì— ìµœì í™”ëœ ë²„ì „ (Top-3 ìš°ì„ ìˆœìœ„ í ì ìš©)"""

    with transactional_session(db) as session:
        emotion_id, probabilities = predict_emotion(diary_request.content)
        logger.info(f"[ê°ì • ë¶„ì„ ê²°ê³¼] ê°ì • ID: {emotion_id} | ì‹ ë¢°ë„: {probabilities[emotion_id]:.4f}")
        confidence = probabilities[emotion_id]

        emotion_id_db = model_index_to_db_emotion_id[emotion_id]

        # 1) ë¬¸ì¥ ë¶„ë¦¬ + KoBERT ì„ë² ë”©
        sentences = [s.strip() for s in split_sentences(diary_request.content) if s.strip()]
        if not sentences:
            raise HTTPException(status_code=400, detail="ë¶„ì„í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤")

        embeddings = []
        for sentence in sentences:
            try:
                emb = kobert.get_embedding(sentence)
                embeddings.append(emb)
            except Exception as e:
                logger.error(f"ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
        if not embeddings:
            raise HTTPException(status_code=500, detail="ì„ë² ë”© ìƒì„± ì‹¤íŒ¨")

        combined_embedding = np.mean(embeddings, axis=0)

        # 2) ì„ í˜¸ ì¥ë¥´ ì¡°íšŒ
        genre_names = get_user_preferred_genres(session, current_user.id)
        if not genre_names:
            raise HTTPException(status_code=400, detail="ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

        # 3) MongoDBì—ì„œ í•´ë‹¹ ì¥ë¥´ ë…¸ë˜ ê°€ì ¸ì˜¤ê¸°
        songs = await get_songs_by_genre(mongodb, genre_names)
        if not songs:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤")
        logger.info(f"ğŸ¼ [ê°€ì ¸ì˜¨ ë…¸ë˜ ê°œìˆ˜] - {len(songs)}")

        # 4) ìœ ì‚¬ë„ ê³„ì‚° ë° Top-3 ì¶”ì²œê³¡ ì„ ì •
        heap = []
        counter = 0
        for song in songs:
            try:
                song_id = int(song["id"])
                cache_key = f"lyrics_emb:{song_id}"
                cached = await redis.get(cache_key)

                if cached:
                    lyrics_embedding = np.array(json.loads(cached))
                else:
                    result = session.execute(
                        text("SELECT embedding FROM songLyricsEmbedding WHERE song_id = :song_id"),
                        {"song_id": song_id}
                    ).fetchone()
                    if not result:
                        continue
                    lyrics_embedding = np.array(json.loads(result[0]))
                    await redis.set(cache_key, json.dumps(lyrics_embedding.tolist()))

                if len(lyrics_embedding.shape) != 2:
                    continue

                lyrics = song.get("lyrics", [])
                if len(lyrics) < MIN_LYRIC_LINES or len(lyrics_embedding) < LYRIC_WINDOW_SIZE:
                    continue

                for i in range(len(lyrics_embedding) - LYRIC_WINDOW_SIZE + 1):
                    chunk_avg = np.mean(lyrics_embedding[i:i + LYRIC_WINDOW_SIZE], axis=0)

                    similarity = F.cosine_similarity(
                        torch.tensor(combined_embedding).unsqueeze(0),
                        torch.tensor(chunk_avg).unsqueeze(0)
                    ).item()

                    if similarity < 0.7:
                        continue

                    heapq.heappush(heap, (
                        similarity,
                        counter,
                        {
                            "song_id": song["id"],
                            "lyric_chunk": lyrics[i:i + LYRIC_WINDOW_SIZE],
                            "similarity": similarity,
                            "metadata": {
                                "song_name": song.get("song_name"),
                                "album_image": song.get("album_image"),
                                "artist": song.get("artist_name_basket", []),
                                "genre": song.get("genre")
                            }
                        }
                    ))
                    counter += 1

            except Exception as e:
                logger.error(f"ë…¸ë˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        raw_top = heapq.nlargest(10, heap, key=lambda x: (x[0], x[1]))

        # 5) Top-3 ìœ ì‚¬í•œ ë…¸ë˜ ì„ íƒ
        seen_song_ids = set()
        top_3 = []
        for sim, _, match in raw_top:
            if match["song_id"] not in seen_song_ids:
                top_3.append((sim, match))
                seen_song_ids.add(match["song_id"])
            if len(top_3) >= 3:
                break

        if not top_3:
            raise HTTPException(status_code=404, detail="ì í•©í•œ ë…¸ë˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        # 6) ì¼ê¸° ì €ì¥
        new_diary = Diary(
            user_id=current_user.id,
            content=diary_request.content,
            emotiontype_id=emotion_id_db,
            confidence=confidence,
            created_at=datetime.utcnow()
        )
        session.add(new_diary)
        session.commit()
        session.refresh(new_diary)

        # 6-1) ê°ì • í†µê³„ ì—…ë°ì´íŠ¸ or ì¶”ê°€
        existing_stat = session.query(EmotionStatistics).filter(
            EmotionStatistics.user_id == current_user.id,
            extract("year", EmotionStatistics.created_at) == new_diary.created_at.year,
            extract("month", EmotionStatistics.created_at) == new_diary.created_at.month,
            EmotionStatistics.emotiontype_id == emotion_id
        ).first()

        if existing_stat:
            existing_stat.count += 1
            existing_stat.total_diaries += 1
        else:
            new_stat = EmotionStatistics(
                user_id=current_user.id,
                year=new_diary.created_at.year,
                month=new_diary.created_at.month,
                emotiontype_id=emotion_id_db,
                quadrant=None,  # í•„ìš”í•œ ê²½ìš° ê°ì • ID ê¸°ë°˜ìœ¼ë¡œ ë§¤í•‘
                count=1,
                total_diaries=1,
                created_at=new_diary.created_at
            )
            session.add(new_stat)

        # ê°™ì€ ë‹¬ì˜ ë‹¤ë¥¸ ê°ì •ë„ ìˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ, í•´ë‹¹ ë‹¬ ì „ì²´ ì¼ê¸° ìˆ˜ ê¸°ì¤€ìœ¼ë¡œ ë‹¤ë¥¸ ê°ì •ì˜ total_diariesë„ ì—…ë°ì´íŠ¸
        session.query(EmotionStatistics).filter(
            EmotionStatistics.user_id == current_user.id,
            extract("year", EmotionStatistics.created_at) == new_diary.created_at.year,
            extract("month", EmotionStatistics.created_at) == new_diary.created_at.month
        ).update({
            EmotionStatistics.total_diaries: EmotionStatistics.total_diaries + 1
        }, synchronize_session=False)

        # 7) DiaryEmbedding í…Œì´ë¸” ì €ì¥
        session.execute(
            text("INSERT INTO diaryEmbedding (diary_id, embedding) VALUES (:diary_id, :embedding)"),
            {"diary_id": new_diary.id, "embedding": json.dumps(combined_embedding.tolist())}
        )

        # 8) ì‘ë‹µ êµ¬ì„±
        recommended_songs = [
            {
                "song_id": match["song_id"],
                "song_name": match["metadata"]["song_name"],
                "best_lyric": " ".join(match["lyric_chunk"]),
                "similarity_score": round(float(sim), 4),
                "album_image": match["metadata"]["album_image"],
                "artist": match["metadata"]["artist"],
                "genre": match["metadata"]["genre"]
            }
            for sim, match in top_3
        ]

        response_data = {
            "id": new_diary.id,
            "user_id": new_diary.user_id,
            "content": new_diary.content,
            "emotiontype_id": emotion_id_db,
            "confidence": confidence,
            "created_at": new_diary.created_at,
            "updated_at": new_diary.updated_at,
            "recommended_songs": recommended_songs
        }

        logger.info("ì¶”ì²œ ê²°ê³¼: %s", json.dumps(response_data, indent=2, ensure_ascii=False, default=str))
        return response_data



@router.get("/{diary_id}", response_model=DiaryResponse,
            summary="ì¼ê¸° ì¡°íšŒ",
            description="íŠ¹ì • ì¼ê¸°ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_diary(
    diary_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return diary

@router.get("", response_model=List[DiaryResponse],
            summary="ë‚´ ì¼ê¸° ëª©ë¡ ì¡°íšŒ",
            description="ë¡œê·¸ì¸í•œ ì‚¬ìš©ìê°€ ì‘ì„±í•œ ëª¨ë“  ì¼ê¸°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_all_diaries(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diaries = db.query(Diary).filter(
        Diary.user_id == current_user.id
    ).all()

    return diaries

@router.put("/{diary_id}", response_model=DiaryResponse,
            summary="ì¼ê¸° ìˆ˜ì •",
            description="ì‘ì„±í•œ ì¼ê¸°ì˜ ë‚´ìš©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.")
def update_diary(
    diary_id: int,
    diary_update: DiaryUpdateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if diary_update.content:
        diary.content = diary_update.content

    db.commit()
    db.refresh(diary)

    return diary

@router.delete("/{diary_id}",
               summary="ì¼ê¸° ì‚­ì œ",
               description="ì‘ì„±í•œ ì¼ê¸°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
def delete_diary(
    diary_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    db.delete(diary)
    db.commit()

    return {"message": "ì¼ê¸°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!"}

@router.get("/{year}/{month}", response_model=List[DiaryResponse],
            summary="íŠ¹ì • ì—°ë„/ì›”ì˜ ì¼ê¸° ì¡°íšŒ",
            description="ì…ë ¥í•œ ì—°ë„ì™€ ì›”ì— í•´ë‹¹í•˜ëŠ” ì¼ê¸°ë¥¼ ëª¨ë‘ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_diaries_by_month(
    year: int,
    month: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diaries = db.query(Diary).filter(
        Diary.user_id == current_user.id,
        extract("year", Diary.created_at) == year,
        extract("month", Diary.created_at) == month
    ).all()

    if not diaries:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì—°ë„ì™€ ì›”ì— ì‘ì„±ëœ ì¼ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return diaries

