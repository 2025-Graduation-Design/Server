from fastapi import APIRouter, Depends, HTTPException
from sqlalchemy.orm import Session
from sqlalchemy import extract, text, func
from app.database import get_db, get_mongodb, get_redis
from app.emotion.models import model_index_to_db_emotion_id
from app.emotion.router import predict_emotion
from app.statistics.models import EmotionStatistics
from app.user.auth import get_current_user
from app.diary.models import Diary, RecommendedSong
from app.diary.schemas import DiaryCreateRequest, DiaryUpdateRequest, DiaryResponse, DiaryCountResponse, SongResponse, \
    DiaryPreviewResponse
from app.user.models import User
from app.embedding.models import kobert, save_diary_embedding, split_sentences, get_user_preferred_genres, \
    get_songs_by_genre, get_song_embeddings, calculate_similarity
from app.transaction import transactional_session
from typing import List
import logging
import json
import torch
import numpy as np
import heapq
from datetime import datetime

router = APIRouter()

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def get_recently_recommended_song_ids(session, user_id: int, limit: int = 5) -> List[int]:
    """
    ìµœê·¼ ì‘ì„±í•œ ì¼ê¸° ì¤‘ì—ì„œ ì¶”ì²œëœ ë…¸ë˜ ID ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜ (ì¤‘ë³µ ì œê±°)
    """
    subquery = (
        session.query(Diary.id)
        .filter(Diary.user_id == user_id)
        .order_by(Diary.created_at.desc())
        .limit(limit)
        .subquery()
    )

    song_ids = (
        session.query(RecommendedSong.song_id)
        .filter(RecommendedSong.diary_id.in_(subquery))
        .distinct()
        .all()
    )

    # ê²°ê³¼ëŠ” [(song_id1,), (song_id2,), ...] í˜•íƒœì´ë¯€ë¡œ flatten
    return [sid[0] for sid in song_ids]

@router.post("/main", response_model=DiaryResponse, status_code=201,
             summary="ì¼ê¸° ì‘ì„± & Top-3 ìœ ì‚¬ ê°€ì‚¬ ê¸°ë°˜ ë…¸ë˜ ì¶”ì²œ",
             description="ì¼ê¸°ë¥¼ ì‘ì„±í•˜ë©´ KoBERT ì„ë² ë”© í›„, ì„ í˜¸ ì¥ë¥´ ë‚´ì—ì„œ ê°€ì‚¬ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ Top-3 ë…¸ë˜ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.")
async def create_diary_with_music_recommend_top3(
    diary_request: DiaryCreateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    mongodb = Depends(get_mongodb),
    redis = Depends(get_redis)
):
    with transactional_session(db) as session:
        # 1) ë¬¸ì¥ ë¶„ë¦¬
        sentences = split_sentences(diary_request.content)
        if not sentences:
            raise HTTPException(status_code=400, detail="ë¶„ì„í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

        sentence_confidences = []
        emotion_vote_counter = {}

        logger.info("[ë¬¸ì¥ë³„ ê°ì • ë¶„ì„ ì‹œì‘]")
        for idx, sentence in enumerate(sentences):
            if not sentence.strip():
                continue

            logger.info(f"    â–¶ ë¬¸ì¥ {idx + 1}: {sentence}")

            emotion_id, probabilities = predict_emotion(sentence)
            confidence = max(probabilities)

            logger.info(f"       â–¶ ë¬¸ì¥ {idx + 1} ì˜ˆì¸¡ ê°ì • ID: {emotion_id}, í™•ì‹ ë„: {confidence:.4f}")
            sentence_confidences.append((sentence, emotion_id, confidence))

            # Top-3 ê°ì • ëª¨ë‘ ëˆ„ì 
            probs_tensor = torch.tensor(probabilities)
            topk = torch.topk(probs_tensor, k=3)

            for i in range(3):
                emo_id = topk.indices[i].item()
                score = topk.values[i].item()

                if score < 0.05:
                    continue

                if emo_id not in emotion_vote_counter:
                    emotion_vote_counter[emo_id] = 0.0
                emotion_vote_counter[emo_id] += score

        # í™•ì‹ ë„ ì´í•©ì´ ê°€ì¥ ë†’ì€ ê°ì • ì„ íƒ
        emotion_id_full = max(emotion_vote_counter.items(), key=lambda x: x[1])[0]
        confidence_full = emotion_vote_counter[emotion_id_full]
        emotion_id_db = model_index_to_db_emotion_id[emotion_id_full]

        # 3) ì „ì²´ ê°ì • ë¶„ì„ ê²°ê³¼ ì¶œë ¥
        logger.info("[ë¬¸ì¥ë³„ ê°ì • í†µê³„ ê¸°ë°˜ ì „ì²´ ê°ì • ë¶„ì„ ê²°ê³¼]")
        for emo_id, score in sorted(emotion_vote_counter.items(), key=lambda x: -x[1]):
            logger.info(f"    â–¶ ê°ì • ID={emo_id}, í™•ì‹ ë„ ì´í•©={score:.4f}")

        logger.info(f"    â–¶ ìµœì¢… ì „ì²´ ê°ì • ID: {emotion_id_full}, í™•ì‹ ë„ ì´í•©: {confidence_full:.4f}")

        # 4) Top-1 ê°ì •ê³¼ ì¼ì¹˜í•˜ëŠ” ë¬¸ì¥ ì¤‘ ê°€ì¥ í™•ì‹ ë„ ë†’ì€ ë¬¸ì¥ ì„ íƒ
        top1_emotion_id = emotion_id_full  # ëª¨ë¸ ê¸°ì¤€ ê°ì • ID
        filtered_sentences = [
            (sentence, emo_id, conf)
            for sentence, emo_id, conf in sentence_confidences
            if emo_id == top1_emotion_id
        ]

        if not filtered_sentences:
            raise HTTPException(status_code=500, detail="Top ê°ì •ì— í•´ë‹¹í•˜ëŠ” ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

        best_sentence, best_emotion_id, best_confidence = max(filtered_sentences, key=lambda x: x[2])
        logger.info(f"[Top ê°ì •ì—ì„œ ê°€ì¥ ê°•í•œ ë¬¸ì¥ ì„ íƒ] {best_sentence} (ê°ì • ID={best_emotion_id}, í™•ì‹ ë„={best_confidence:.4f})")

        # 5) best_sentenceë¥¼ KoBERT ì„ë² ë”©
        combined_embedding = kobert.get_embedding(best_sentence)

        # 6) ì„ í˜¸ ì¥ë¥´ ì¡°íšŒ
        genre_names = get_user_preferred_genres(session, current_user.id)
        if not genre_names:
            raise HTTPException(status_code=400, detail="ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        # 7) MongoDBì—ì„œ í•´ë‹¹ ì¥ë¥´ ë…¸ë˜ ê°€ì ¸ì˜¤ê¸°
        songs = await get_songs_by_genre(mongodb, genre_names)
        if not songs:
            raise HTTPException(status_code=404, detail="í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")
        logger.info(f"ğŸ¼ [ê°€ì ¸ì˜¨ ë…¸ë˜ ê°œìˆ˜] - {len(songs)}")

        # 8) ìœ ì‚¬ë„ ê³„ì‚° ë° Top-3 ì¶”ì²œê³¡ ì„ ì •
        heap = []
        counter = 0

        # 1) ê³¡ ID ì¶”ì¶œ
        song_id_map = {int(song["id"]): song for song in songs}
        song_ids = list(song_id_map.keys())
        cache_keys = [f"lyrics_emb:{song_id}" for song_id in song_ids]

        # 2) Redis ì¼ê´„ ì¡°íšŒ
        cached_values = await redis.mget(cache_keys)

        # 3) ìœ ì‚¬ë„ ê³„ì‚°
        combined_np = np.array(combined_embedding)  # (768,)
        for song_id, cached in zip(song_ids, cached_values):
            try:
                if cached:
                    lyrics_embedding = np.array(json.loads(cached))
                else:
                    result = session.execute(
                        text("SELECT embedding FROM songLyricsEmbedding WHERE song_id = :song_id"),
                        {"song_id": song_id}
                    ).fetchone()
                    if not result:
                        continue
                    lyrics_embedding = np.array(json.loads(result[0]))
                    await redis.set(f"lyrics_emb:{song_id}", json.dumps(lyrics_embedding.tolist()), ex=60*60*24*30)

                if len(lyrics_embedding.shape) != 2:
                    continue

                song = song_id_map[song_id]
                lyrics = song.get("lyrics", [])
                if len(lyrics) < 1 or len(lyrics_embedding) != len(lyrics):
                    continue

                # 4) ì „ì²´ ë¸”ëŸ­ê³¼ ìœ ì‚¬ë„ í•œ ë²ˆì— ê³„ì‚°
                dot = np.dot(lyrics_embedding, combined_np)  # (n,)
                norm_block = np.linalg.norm(lyrics_embedding, axis=1)
                norm_query = np.linalg.norm(combined_np)
                similarities = dot / (norm_block * norm_query + 1e-8)

                for idx, similarity in enumerate(similarities):
                    heapq.heappush(heap, (
                        similarity,
                        counter,
                        {
                            "song_id": song_id,
                            "lyric_chunk": [lyrics[idx]],
                            "similarity": similarity,
                            "metadata": {
                                "song_name": song.get("song_name"),
                                "album_image": song.get("album_image"),
                                "artist": song.get("artist_name_basket", []),
                                "genre": song.get("genre")
                            }
                        }
                    ))
                    counter += 1

            except Exception as e:
                logger.error(f"ë…¸ë˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue

        # ì´í›„ raw_top, top_3, recommended_songs ìƒì„±ì€ ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ ìœ ì§€
        raw_top = heapq.nlargest(10, heap, key=lambda x: (x[0], x[1]))

        recent_song_ids = get_recently_recommended_song_ids(session, user_id=current_user.id, limit=5)

        seen_song_ids = set()
        top_3 = []
        for sim, _, match in raw_top:
            song_id = match["song_id"]

            if song_id in seen_song_ids:
                continue

            if song_id in recent_song_ids:
                logger.info(f"ìµœê·¼ ì¶”ì²œëœ ê³¡ {song_id} ì œì™¸")
                continue

            top_3.append((sim, match))
            seen_song_ids.add(song_id)

            if len(top_3) >= 3:
                break

        if not top_3:
            raise HTTPException(status_code=404, detail="ì í•©í•œ ë…¸ë˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 9) ì¼ê¸° ì €ì¥
        new_diary = Diary(
            user_id=current_user.id,
            content=diary_request.content,
            emotiontype_id=emotion_id_db,
            confidence=confidence_full,
            best_sentence=best_sentence,
            created_at=datetime.utcnow()
        )
        session.add(new_diary)
        session.commit()
        session.refresh(new_diary)

        save_diary_embedding(session, new_diary.id, combined_embedding)

        recommended_songs = [
            {
                "song_id": match["song_id"],
                "song_name": match["metadata"]["song_name"],
                "best_lyric": " ".join(match["lyric_chunk"]),
                "similarity_score": round(float(sim), 4),
                "album_image": match["metadata"]["album_image"],
                "artist": match["metadata"]["artist"],
                "genre": match["metadata"]["genre"]
            }
            for sim, match in top_3
        ]

        for song_data in recommended_songs:
            new_song = RecommendedSong(
                diary_id=new_diary.id,
                song_id=song_data["song_id"],  # MongoDB ID ë¬¸ìì—´ ë³€í™˜
                song_name=song_data["song_name"],
                artist=song_data["artist"],
                genre=song_data["genre"],
                album_image=song_data["album_image"],
                best_lyric=song_data["best_lyric"],
                similarity_score=song_data["similarity_score"]
            )
            session.add(new_song)

        # 9-1) ê°ì • í†µê³„ ì—…ë°ì´íŠ¸ ë˜ëŠ” ì¶”ê°€
        existing_stat = session.query(EmotionStatistics).filter(
            EmotionStatistics.user_id == current_user.id,
            EmotionStatistics.year == new_diary.created_at.year,
            EmotionStatistics.month == new_diary.created_at.month,
            EmotionStatistics.emotiontype_id == emotion_id_db
        ).first()

        if existing_stat:
            existing_stat.count += 1
        else:
            new_stat = EmotionStatistics(
                user_id=current_user.id,
                year=new_diary.created_at.year,
                month=new_diary.created_at.month,
                emotiontype_id=emotion_id_db,
                quadrant=None,  # quadrant ë‚˜ì¤‘ì— ì¶”ê°€í• ê±°ë©´ ë§¤í•‘
                count=1,
                created_at=new_diary.created_at
            )
            session.add(new_stat)

        session.commit()

        # 10) ì‘ë‹µ êµ¬ì„±
        response_data = {
            "id": new_diary.id,
            "user_id": new_diary.user_id,
            "content": new_diary.content,
            "emotiontype_id": emotion_id_db,
            "confidence": confidence_full,
            "created_at": new_diary.created_at,
            "updated_at": new_diary.updated_at,
            "recommended_songs": recommended_songs,
            "top_emotions": [{"emotion_id": emo_id, "score": round(score, 4)}
                            for emo_id, score in sorted(emotion_vote_counter.items(), key=lambda x: -x[1])[:3]]
        }

        logger.info("ì¶”ì²œ ê²°ê³¼: %s", json.dumps(response_data, indent=2, ensure_ascii=False, default=str))
        return response_data

@router.post("/preview", summary="ì¼ê¸° ê°ì • ë¶„ì„ + ì¶”ì²œ ë¯¸ë¦¬ë³´ê¸°", response_model=DiaryPreviewResponse)
async def preview_diary_with_music_recommend_top3(
    diary_request: DiaryCreateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db),
    mongodb = Depends(get_mongodb),
    redis = Depends(get_redis)
):
    sentences = split_sentences(diary_request.content)
    if not sentences:
        raise HTTPException(status_code=400, detail="ë¶„ì„í•  ë¬¸ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")

    sentence_emotions = []
    sentence_confidences = []
    emotion_vote_counter = {}

    for sentence in sentences:
        emotion_id, probabilities = predict_emotion(sentence)
        confidence = max(probabilities)

        topk = torch.topk(torch.tensor(probabilities), k=3)
        top3 = [
            {"emotion_id": topk.indices[i].item(), "score": round(topk.values[i].item(), 4)}
            for i in range(3) if topk.values[i].item() >= 0.01
        ]

        sentence_confidences.append((sentence, emotion_id, confidence))
        sentence_emotions.append({
            "sentence": sentence,
            "predicted_emotion_id": emotion_id,
            "confidence": round(confidence, 4),
            "top3": top3
        })

        for i in range(3):
            emo_id = topk.indices[i].item()
            score = topk.values[i].item()
            if score < 0.05:
                continue
            emotion_vote_counter[emo_id] = emotion_vote_counter.get(emo_id, 0) + score

    if not emotion_vote_counter:
        raise HTTPException(status_code=500, detail="ê°ì • ë¶„ì„ ì‹¤íŒ¨")

    top1_emotion_id = max(emotion_vote_counter.items(), key=lambda x: x[1])[0]
    confidence_full = emotion_vote_counter[top1_emotion_id]
    emotion_id_db = model_index_to_db_emotion_id[top1_emotion_id]

    # Top ê°ì • ê¸°ì¤€ ê°€ì¥ ê°•í•œ ë¬¸ì¥
    filtered_sentences = [
        (s, eid, c) for (s, eid, c) in sentence_confidences if eid == top1_emotion_id
    ]
    if not filtered_sentences:
        raise HTTPException(status_code=500, detail="Top ê°ì • ë¬¸ì¥ ì—†ìŒ")
    best_sentence, best_emotion_id, best_confidence = max(filtered_sentences, key=lambda x: x[2])

    combined_embedding = kobert.get_embedding(best_sentence)

    genre_names = get_user_preferred_genres(db, current_user.id)
    if not genre_names:
        raise HTTPException(status_code=400, detail="ì„ í˜¸ ì¥ë¥´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    songs = await get_songs_by_genre(mongodb, genre_names)
    if not songs:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì¥ë¥´ì— ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

    heap = []
    counter = 0
    song_id_map = {int(song["id"]): song for song in songs}
    song_ids = list(song_id_map.keys())
    cache_keys = [f"lyrics_emb:{song_id}" for song_id in song_ids]
    cached_values = await redis.mget(cache_keys)

    combined_np = np.array(combined_embedding)
    for song_id, cached in zip(song_ids, cached_values):
        try:
            if cached:
                lyrics_embedding = np.array(json.loads(cached))
            else:
                result = db.execute(
                    text("SELECT embedding FROM songLyricsEmbedding WHERE song_id = :song_id"),
                    {"song_id": song_id}
                ).fetchone()
                if not result:
                    continue
                lyrics_embedding = np.array(json.loads(result[0]))
                await redis.set(f"lyrics_emb:{song_id}", json.dumps(lyrics_embedding.tolist()), ex=60*60*24*30)

            if len(lyrics_embedding.shape) != 2:
                continue

            song = song_id_map[song_id]
            lyrics = song.get("lyrics", [])
            if len(lyrics) < 1 or len(lyrics_embedding) != len(lyrics):
                continue

            dot = np.dot(lyrics_embedding, combined_np)
            norm_block = np.linalg.norm(lyrics_embedding, axis=1)
            norm_query = np.linalg.norm(combined_np)
            similarities = dot / (norm_block * norm_query + 1e-8)

            for idx, similarity in enumerate(similarities):
                heapq.heappush(heap, (
                    similarity,
                    counter,
                    {
                        "song_id": song_id,
                        "lyric_chunk": [lyrics[idx]],
                        "similarity": similarity,
                        "metadata": {
                            "song_name": song.get("song_name"),
                            "album_image": song.get("album_image"),
                            "artist": song.get("artist_name_basket", []),
                            "genre": song.get("genre")
                        }
                    }
                ))
                counter += 1
        except Exception as e:
            logger.error(f"[preview] ë…¸ë˜ ìœ ì‚¬ë„ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            continue

    raw_top = heapq.nlargest(10, heap, key=lambda x: (x[0], x[1]))
    seen_song_ids = set()
    top_3 = []
    for sim, _, match in raw_top:
        if match["song_id"] not in seen_song_ids:
            top_3.append((sim, match))
            seen_song_ids.add(match["song_id"])
        if len(top_3) >= 3:
            break

    if not top_3:
        raise HTTPException(status_code=404, detail="ì í•©í•œ ë…¸ë˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    recommended_songs = [
        {
            "song_id": match["song_id"],
            "song_name": match["metadata"]["song_name"],
            "best_lyric": " ".join(match["lyric_chunk"]),
            "similarity_score": round(float(sim), 4),
            "album_image": match["metadata"]["album_image"],
            "artist": match["metadata"]["artist"],
            "genre": match["metadata"]["genre"]
        }
        for sim, match in top_3
    ]

    return {
        "id": -1,
        "user_id": current_user.id,
        "content": diary_request.content,
        "emotiontype_id": emotion_id_db,
        "confidence": confidence_full,
        "created_at": datetime.utcnow(),
        "updated_at": datetime.utcnow(),
        "recommended_songs": recommended_songs,
        "top_emotions": [
            {"emotion_id": emo_id, "score": round(score, 4)}
            for emo_id, score in sorted(emotion_vote_counter.items(), key=lambda x: -x[1])[:3]
        ],
        "best_sentence": {
            "sentence": best_sentence,
            "predicted_emotion_id": best_emotion_id,
            "confidence": round(best_confidence, 4)
        },
        "sentence_emotions": sentence_emotions
    }

@router.get("/{diary_id}", response_model=DiaryResponse,
            summary="ì¼ê¸° ì¡°íšŒ",
            description="íŠ¹ì • ì¼ê¸°ì˜ ìƒì„¸ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_diary(
    diary_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    return diary

@router.get("/{diary_id}/recommended-songs", response_model=list[SongResponse],
            summary="ì¶”ì²œ ë…¸ë˜ ì¡°íšŒ",
            description="íŠ¹ì • ì¼ê¸°ì— ëŒ€í•œ ì¶”ì²œ ë…¸ë˜ ë¦¬ìŠ¤íŠ¸ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_recommended_songs_by_diary(
    diary_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    # 1. í•´ë‹¹ ì¼ê¸°ê°€ ìœ ì €ì˜ ê²ƒì¸ì§€ ê²€ì¦
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # 2. ì¶”ì²œê³¡ ì¡°íšŒ
    songs = db.query(RecommendedSong).filter(
        RecommendedSong.diary_id == diary_id
    ).order_by(RecommendedSong.similarity_score.desc()).all()

    if not songs:
        raise HTTPException(status_code=404, detail="ì¶”ì²œëœ ë…¸ë˜ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return songs

@router.get("", response_model=List[DiaryResponse],
            summary="ë‚´ ì¼ê¸° ëª©ë¡ ì¡°íšŒ",
            description="ë¡œê·¸ì¸í•œ ì‚¬ìš©ìê°€ ì‘ì„±í•œ ëª¨ë“  ì¼ê¸°ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_all_diaries(
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diaries = db.query(Diary).filter(
        Diary.user_id == current_user.id
    ).all()

    return diaries

@router.put("/{diary_id}", response_model=DiaryResponse,
            summary="ì¼ê¸° ìˆ˜ì •",
            description="ì‘ì„±í•œ ì¼ê¸°ì˜ ë‚´ìš©ì„ ìˆ˜ì •í•©ë‹ˆë‹¤.")
def update_diary(
    diary_id: int,
    diary_update: DiaryUpdateRequest,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    if diary_update.content:
        diary.content = diary_update.content

    db.commit()
    db.refresh(diary)

    return diary

@router.delete("/{diary_id}",
               summary="ì¼ê¸° ì‚­ì œ",
               description="ì‘ì„±í•œ ì¼ê¸°ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.")
def delete_diary(
    diary_id: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diary = db.query(Diary).filter(
        Diary.id == diary_id,
        Diary.user_id == current_user.id
    ).first()

    if not diary:
        raise HTTPException(status_code=404, detail="ì¼ê¸°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    db.delete(diary)
    db.commit()

    return {"message": "ì¼ê¸°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤!"}

@router.get("/{year}/{month}", response_model=List[DiaryResponse],
            summary="íŠ¹ì • ì—°ë„/ì›”ì˜ ì¼ê¸° ì¡°íšŒ",
            description="ì…ë ¥í•œ ì—°ë„ì™€ ì›”ì— í•´ë‹¹í•˜ëŠ” ì¼ê¸°ë¥¼ ëª¨ë‘ ì¡°íšŒí•©ë‹ˆë‹¤.")
def get_diaries_by_month(
    year: int,
    month: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    diaries = db.query(Diary).filter(
        Diary.user_id == current_user.id,
        extract("year", Diary.created_at) == year,
        extract("month", Diary.created_at) == month
    ).all()

    if not diaries:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ ì—°ë„ì™€ ì›”ì— ì‘ì„±ëœ ì¼ê¸°ê°€ ì—†ìŠµë‹ˆë‹¤.")

    return diaries


@router.get("/{year}/{month}/count", response_model=DiaryCountResponse,
            summary="íŠ¹ì • ì—°/ì›”ì˜ ì¼ê¸° ê°œìˆ˜ ì¡°íšŒ",
            description="ì…ë ¥í•œ ì—°ë„ì™€ ì›”ì— í•´ë‹¹í•˜ëŠ” ì¼ê¸° ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.")
def get_diary_count_by_month(
    year: int,
    month: int,
    current_user: User = Depends(get_current_user),
    db: Session = Depends(get_db)
):
    if month < 1 or month > 12:
        raise HTTPException(status_code=400, detail="ì›”(month)ì€ 1~12 ì‚¬ì´ì—¬ì•¼ í•©ë‹ˆë‹¤.")

    diary_count = db.query(func.count(Diary.id)).filter(
        Diary.user_id == current_user.id,
        extract("year", Diary.created_at) == year,
        extract("month", Diary.created_at) == month
    ).scalar()

    return DiaryCountResponse(
        user_id=current_user.id,
        year=year,
        month=month,
        diary_count=diary_count
    )
